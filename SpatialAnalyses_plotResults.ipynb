{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Analyses script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses the resuilts from the temporally-specific analyses (aka the results from \"TemporallySpecificAnalyses_SVC_mainFunctions\" to uncover the spatial patterns underlying each significant cluster.\n",
    "\n",
    "This script is responsible for the spatial analyses and figures in the results, as well as the related supplemental figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bachmanm\\AppData\\Local\\Temp\\ipykernel_16300\\1491564398.py:11: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 40em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%run EEG_auxiliary_module_sptm_wICA.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "#import statsmodels.stats.multitest.multipletests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "from IPython.core.debugger import set_trace\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "display(HTML(\"<style>div.output_scroll { height: 40em; }</style>\"))\n",
    "#disable sklearn warnings\n",
    "import sys\n",
    "from scipy import signal as signal\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    os.environ['PYTHONWARNINGS']='ignore'\n",
    "    \n",
    "from scipy.spatial.distance import  squareform\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the group-averaged model coefs per stimulus in a defined time range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output the average and individual topomaps for a certain condition and certain timerange.\n",
    "\n",
    "It will also output both the classifier filters and patterns. The latter is only used because it is more neurophysiologically interpretable.\n",
    "\n",
    "Adjust lines 80 and 81 in the cell below to point to the output from \"TemporallySpecificAnalyses_SVC_mainFunctions.\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_weights_per_stim (cond_main,event_main, time1, time2):\n",
    "#     set_trace()\n",
    "    subjects = [str(s) for s in [150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,166,167,168,169,170,171,173,174,176,177,178,180,181,182,183,185,186,188,189,190,191,192,193,194,195]]\n",
    "    multiclass  = 'binary'#['binary','multi']\n",
    "    \n",
    "    \n",
    "    coefsFile        = os.path.join('GroupResults','guggenmos_noJitFix','groupCoefs'+event_main+cond_main+str(time1)+'-'+str(time2)+'_v2_reref.npy')\n",
    "    coefsFile_scaled = os.path.join('GroupResults','guggenmos_noJitFix','groupCoefs_scaled'+event_main+cond_main+str(time1)+'-'+str(time2)+'_v2_reref.npy')\n",
    "\n",
    "#     %matplotlib qt\n",
    "\n",
    "    if event_main == 'Stimulus':\n",
    "        times = np.linspace(-200,1000,120)\n",
    "    elif event_main == 'Dot':\n",
    "        times = np.linspace(800,2000,120)\n",
    "    elif event_main == 'Stimulus_long':\n",
    "        times = np.linspace(-200,2000,220)\n",
    "    \n",
    "    condWord = cond_main+'s'\n",
    "    numClasses = 5\n",
    "    \n",
    "    if cond_main == 'Response-0' or cond_main == 'Value_absMag' or cond_main == 'Value_binary':\n",
    "        condWord = cond_main\n",
    "        numClasses = 2\n",
    "        \n",
    "    if cond_main == 'Value_absMag_v2' or cond_main == 'Value_binary_v2':\n",
    "        condWord = cond_main\n",
    "        numClasses = 3\n",
    "        \n",
    "    if cond_main == 'Value-2':\n",
    "        condWord = cond_main   \n",
    "        numClasses = 5 # 2 classes only 1 set of coefs\n",
    "    \n",
    "    print(condWord)\n",
    "    \n",
    "    # This is fixes the z-limits for each plot. They are manually set based on the absolute maximum value for each condition.\n",
    "    if cond_main == 'Face':\n",
    "        vmaxAbs = .004 # For Faces\n",
    "        vmaxAbs_sep = .004 \n",
    "    elif cond_main =='Color': \n",
    "        vmaxAbs = .001 # For Colors\n",
    "        vmaxAbs_sep = .003 \n",
    "    elif cond_main == 'FaceValue':\n",
    "        vmaxAbs = .005 # For FaceValues\n",
    "        vmaxAbs_sep = .008\n",
    "    elif cond_main =='ColorValue': \n",
    "        vmaxAbs = .004 # For ColorValues\n",
    "        vmaxAbs_sep = 0.010\n",
    "    elif cond_main =='Value-2': \n",
    "        vmaxAbs = .007 # For Value-2\n",
    "        vmaxAbs_sep = 0.019\n",
    "    elif cond_main =='Response-0': \n",
    "        vmaxAbs = .007 # For Response-0\n",
    "        vmaxAbs_sep = .007 \n",
    "    elif cond_main =='Value_absMag': \n",
    "        vmaxAbs = .006 # For Value_absMag\n",
    "    elif cond_main =='Value_absMag_v2': \n",
    "        vmaxAbs = .003 # For Value_absMag_v2\n",
    "    elif cond_main =='Value_binary': \n",
    "        vmaxAbs = .009 # For Value_binary\n",
    "    elif cond_main =='Value_binary_v2': \n",
    "        vmaxAbs = .004 # For Value_binary_v2  \n",
    "    \n",
    "        \n",
    "    t_ind1 = find_nearest_idx(time1,times)\n",
    "    t_ind2 = find_nearest_idx(time2,times)\n",
    "\n",
    "    eegData, _, _ = get_eeg_behav_data('102')\n",
    "    infoStructure = eegData.info\n",
    "    del eegData\n",
    "\n",
    "    if os.path.exists(coefsFile):\n",
    "        coefs_all        = np.load(coefsFile)\n",
    "        coefs_all_scaled = np.load(coefsFile_scaled)\n",
    "    else:\n",
    "        coefs_all        = np.zeros((len(subjects),numClasses,64))\n",
    "        coefs_all_scaled = np.zeros((len(subjects),numClasses,64))\n",
    "\n",
    "        for s, subj in enumerate(subjects):\n",
    "            coefs = np.load(os.path.join('Results',subj,'classification_guggenmos_noJitFix','coefs_'+condWord+'_'+event_main+'_10ms_v2_reref.npy'))\n",
    "            coefs_scaled = np.load(os.path.join('Results',subj,'classification_guggenmos_noJitFix','coefs_scaled_'+condWord+'_'+event_main+'_10ms_v2_reref.npy'))\n",
    "                        \n",
    "            coefs        = np.nanmean(coefs[:,:,:,t_ind1:t_ind2+1],axis = -1)\n",
    "            coefs_scaled = np.nanmean(coefs_scaled[:,:,:,t_ind1:t_ind2+1],axis = -1)\n",
    "#             set_trace()\n",
    "            for ch in range(coefs.shape[-1]):\n",
    "                #get the confusion matrix for stimuli\n",
    "                temp  = coefs[:,:,ch].copy()\n",
    "                temp2 = coefs_scaled[:,:,ch].copy()\n",
    "#                 set_trace()\n",
    "                if numClasses > 2:\n",
    "                    #Fill both sides of the diagonal to be able to extract the mean by np.nanmean\n",
    "                    for i in range(1,temp.shape[0]):\n",
    "                        for j in range(i):\n",
    "                            temp[i,j]  = temp[j,i]\n",
    "                            temp2[i,j] = temp2[j,i]                    \n",
    "                \n",
    "                coefs_all[s,:,ch]        = np.nanmean(temp, axis = 0).transpose()\n",
    "                coefs_all_scaled[s,:,ch] = np.nanmean(temp2, axis = 0).transpose()\n",
    "#         set_trace()\n",
    "        np.save(coefsFile,coefs_all)\n",
    "        np.save(coefsFile_scaled,coefs_all_scaled)\n",
    "        \n",
    "#     set_trace()\n",
    "    coefMean        = np.mean(coefs_all,0)\n",
    "    coefMean_scaled = np.mean(coefs_all_scaled,0)\n",
    "    \n",
    "    ### plot pattern for each stimulus\n",
    "    if numClasses > 2:\n",
    "        for ss in range(coefMean.shape[0]):\n",
    "            fig, axes = plt.subplots(1,2)\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title('coefs', pad= 1)\n",
    "            [title_txt, absmax] = plot_scalpmap(coefMean[ss,:], infoStructure,times[t_ind1],timeWindow=None)\n",
    "\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title('coefs_scaled', pad= 1)\n",
    "            [title_txt,absmax] = plot_scalpmap(coefMean_scaled[ss,:], infoStructure,times[t_ind1],timeWindow=None,vrange=vmaxAbs_sep)\n",
    "\n",
    "\n",
    "            figname = 'pattern' + event_main + cond_main + str(ss+1)+' ' + str(time1)+'-'+str(time2)+'ms_fixedRange_reref.eps'\n",
    "            savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection_reref',figname)\n",
    "            plt.suptitle(cond_main.replace('-','') + '-' + str(ss+1) + ' ' + str(time1)+'-'+str(time2)+'ms',x=.5, y=.85)\n",
    "            plt.savefig(savefig,format='eps')\n",
    "\n",
    "    ## plot averaged pattern\n",
    "    fig, axes = plt.subplots()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('coefs', pad= 1)\n",
    "\n",
    "    [title_txt,absmax] = plot_scalpmap(np.nanmean(coefMean,0), infoStructure,times[t_ind1],timeWindow=None)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('coefs_scaled', pad= 1)\n",
    "    [title_txt,absmax] = plot_scalpmap(np.nanmean(coefMean_scaled,0), infoStructure,times[t_ind1],timeWindow=None,vrange=vmaxAbs)\n",
    "   \n",
    "\n",
    "    figname = 'pattern' + event_main + cond_main + 'Avg'+' ' + str(time1)+'-'+str(time2)+'ms_fixedRange_reref.eps'\n",
    "    savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection_reref',figname)\n",
    "    plt.suptitle(cond_main.replace('-','') + ' AvgStim' + ' ' + str(time1)+'-'+str(time2)+'ms',x=.5, y=.85)\n",
    "    plt.savefig(savefig,format='eps')\n",
    "\n",
    "    cond_main_Weights = coefMean\n",
    "    cond_main_Patterns = coefs_all_scaled\n",
    "    return cond_main_Weights, cond_main_Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Time ranges for significant decoding activity in the temporally-specific classifiers.\n",
    "\n",
    "#Face: 90 to 1300\n",
    "#Color: 80 to 650\n",
    "#FaceV: 450 to 1410, 1560 to 1710\n",
    "#ColorV: 100 to 190, 220 to 380, 450 to 660\n",
    "#Value-2: 600 to 780, 990 to 1090, 1280 to 1410, 1430 to 1520, 1550 to 1680\n",
    "# response 620 to 860, 970 to 1170, 1190 to 1510, 1810 to 1880\n",
    "# 'Value_absMag: 1270 to 1430\n",
    "# 'Value_absMag_v2: 110 to 210, 930 to 1010, 1030 to 1120, 1170 to 1830, 1850 to 1990\n",
    "# 'Value_binary: 620 to 790, 870 to 1790\n",
    "# 'Value_binary_v2: 310 to 390, 450 to 1910, 1930 to 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces\n",
      "0.010888659966738845\n",
      "0.004\n",
      "0.006987487617503405\n",
      "0.004\n",
      "0.00460460467337282\n",
      "0.004\n",
      "0.0072327713380831325\n",
      "0.004\n",
      "0.009307438946817563\n",
      "0.004\n",
      "0.005547114632823987\n",
      "0.004\n",
      "FaceValues\n",
      "0.009516396390111054\n",
      "0.008\n",
      "0.008206849560185048\n",
      "0.008\n",
      "0.005526406765188402\n",
      "0.008\n",
      "0.005257058945741966\n",
      "0.008\n",
      "0.01123657093612144\n",
      "0.008\n",
      "0.007386505094778384\n",
      "0.005\n",
      "FaceValues\n",
      "0.010862523306789652\n",
      "0.008\n",
      "0.005487362601334872\n",
      "0.008\n",
      "0.0044554544287267895\n",
      "0.008\n",
      "0.0060745039680624256\n",
      "0.008\n",
      "0.011183307877603462\n",
      "0.008\n",
      "0.0060782097176301465\n",
      "0.005\n",
      "Colors\n",
      "0.012981261417722758\n",
      "0.003\n",
      "0.006217227755726066\n",
      "0.003\n",
      "0.005279215186192063\n",
      "0.003\n",
      "0.005766572753691905\n",
      "0.003\n",
      "0.009415957307672895\n",
      "0.003\n",
      "0.006084099187005314\n",
      "0.001\n",
      "ColorValues\n",
      "0.013941043666192773\n",
      "0.01\n",
      "0.008949682111859413\n",
      "0.01\n",
      "0.006654537606684036\n",
      "0.01\n",
      "0.010113721042371421\n",
      "0.01\n",
      "0.010267166714582188\n",
      "0.01\n",
      "0.00870327288988475\n",
      "0.004\n",
      "ColorValues\n",
      "0.012745354896669291\n",
      "0.01\n",
      "0.005918256071040294\n",
      "0.01\n",
      "0.005306863166737738\n",
      "0.01\n",
      "0.009023940985199748\n",
      "0.01\n",
      "0.013248756631856849\n",
      "0.01\n",
      "0.0068201961240091785\n",
      "0.004\n",
      "ColorValues\n",
      "0.011446769713593196\n",
      "0.01\n",
      "0.007178702673651933\n",
      "0.01\n",
      "0.005485298757826329\n",
      "0.01\n",
      "0.006145136374695377\n",
      "0.01\n",
      "0.015341193186494928\n",
      "0.01\n",
      "0.006770271295431797\n",
      "0.004\n",
      "Value-2\n",
      "0.010801363678806183\n",
      "0.019\n",
      "0.009723580476400848\n",
      "0.019\n",
      "0.008365537843811497\n",
      "0.019\n",
      "0.009822743939118144\n",
      "0.019\n",
      "0.020798861072010073\n",
      "0.019\n",
      "0.009268177950285207\n",
      "0.007\n",
      "Value-2\n",
      "0.008832525892349398\n",
      "0.019\n",
      "0.007872098504730864\n",
      "0.019\n",
      "0.006631767557989911\n",
      "0.019\n",
      "0.006384494658223379\n",
      "0.019\n",
      "0.012798178892225487\n",
      "0.019\n",
      "0.0077046815848140745\n",
      "0.007\n",
      "Value-2\n",
      "0.008376732719198674\n",
      "0.019\n",
      "0.008118786567007118\n",
      "0.019\n",
      "0.006326606653937135\n",
      "0.019\n",
      "0.00717158344547129\n",
      "0.019\n",
      "0.011632984545120118\n",
      "0.019\n",
      "0.006807564640365196\n",
      "0.007\n",
      "Value-2\n",
      "0.008744800890646418\n",
      "0.019\n",
      "0.008621651712248535\n",
      "0.019\n",
      "0.007007654512400577\n",
      "0.019\n",
      "0.00792961158712741\n",
      "0.019\n",
      "0.012695991263120075\n",
      "0.019\n",
      "0.00728492910043111\n",
      "0.007\n",
      "Value-2\n",
      "0.010311751646712747\n",
      "0.019\n",
      "0.007697614660969024\n",
      "0.019\n",
      "0.006313859437230796\n",
      "0.019\n",
      "0.005790013473010021\n",
      "0.019\n",
      "0.012487863648348224\n",
      "0.019\n",
      "0.007467996737816718\n",
      "0.007\n",
      "Response-0\n",
      "0.015767299268998176\n",
      "0.007\n",
      "Response-0\n",
      "0.01620578497627235\n",
      "0.007\n",
      "Response-0\n",
      "0.012523213074494204\n",
      "0.007\n",
      "Response-0\n",
      "0.012196860889225182\n",
      "0.007\n"
     ]
    }
   ],
   "source": [
    "## Extract the average topos for each cluster in each condition.\n",
    "cond_main_Weights,Face_Percp1_Patterns = get_main_weights_per_stim ('Face','Stimulus_long', 90, 1300)\n",
    "cond_main_Weights,Face_Value1_Patterns = get_main_weights_per_stim ('FaceValue','Stimulus_long', 450, 1410)\n",
    "cond_main_Weights,Face_Value2_Patterns = get_main_weights_per_stim ('FaceValue','Stimulus_long', 1560, 1710)\n",
    "cond_main_Weights,Color_Percp1_Patterns = get_main_weights_per_stim ('Color','Stimulus_long', 80, 650)\n",
    "cond_main_Weights,Color_Value1_Patterns = get_main_weights_per_stim ('ColorValue','Stimulus_long', 100,190)\n",
    "cond_main_Weights,Color_Value2_Patterns = get_main_weights_per_stim ('ColorValue','Stimulus_long', 220,380)\n",
    "cond_main_Weights,Color_Value3_Patterns = get_main_weights_per_stim ('ColorValue','Stimulus_long', 450,660)\n",
    "cond_main_Weights,Overall_Value1_Patterns = get_main_weights_per_stim ('Value-2','Stimulus_long', 600,780)\n",
    "cond_main_Weights,Overall_Value2_Patterns = get_main_weights_per_stim ('Value-2','Stimulus_long', 990,1090)\n",
    "cond_main_Weights,Overall_Value3_Patterns = get_main_weights_per_stim ('Value-2','Stimulus_long', 1280,1410)\n",
    "cond_main_Weights,Overall_Value4_Patterns = get_main_weights_per_stim ('Value-2','Stimulus_long', 1430,1520)\n",
    "cond_main_Weights,Overall_Value5_Patterns = get_main_weights_per_stim ('Value-2','Stimulus_long', 1550,1680)\n",
    "cond_main_Weights,Response1_Patterns = get_main_weights_per_stim ('Response-0','Stimulus_long', 620, 860)\n",
    "cond_main_Weights,Response2_Patterns = get_main_weights_per_stim ('Response-0','Stimulus_long', 970, 1170)\n",
    "cond_main_Weights,Response3_Patterns = get_main_weights_per_stim ('Response-0','Stimulus_long', 1190, 1510)\n",
    "cond_main_Weights,Response4_Patterns = get_main_weights_per_stim ('Response-0','Stimulus_long', 1810, 1880)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now I'm going to 1) make a mean cluster across all types and clusters, correlate those with other categories, and test the overall difference.\n",
    "import scipy\n",
    "Face_Percep_Cluster = np.nanmean(Face_Percp1_Patterns,axis=1)\n",
    "Face_Value_Cluster = (np.nanmean(Face_Value1_Patterns,axis=1) + np.nanmean(Face_Value2_Patterns,axis=1))/2\n",
    "Color_Percep_Cluster = np.nanmean(Color_Percp1_Patterns,axis=1)\n",
    "Color_Value_Cluster = (np.nanmean(Color_Value1_Patterns,axis=1) + np.nanmean(Color_Value2_Patterns,axis=1)+ np.nanmean(Color_Value3_Patterns,axis=1) )/3\n",
    "Overall_Value_Cluster = (np.nanmean(Overall_Value1_Patterns,axis=1) + np.nanmean(Overall_Value2_Patterns,axis=1)+ np.nanmean(Overall_Value3_Patterns,axis=1)+ np.nanmean(Overall_Value4_Patterns,axis=1)+ np.nanmean(Overall_Value5_Patterns,axis=1))/5\n",
    "Response_Cluster = (np.nanmean(Response1_Patterns,axis=1) + np.nanmean(Response2_Patterns,axis=1)+ np.nanmean(Response3_Patterns,axis=1) + np.nanmean(Response4_Patterns,axis=1))/4\n",
    "\n",
    "\n",
    "FaceP_vs_FaceV = []\n",
    "ColorP_vs_ColorV = []\n",
    "FaceV_vs_ColorV = []\n",
    "FaceV_vs_OverallV = []\n",
    "ColorV_vs_OverallV = []\n",
    "OverallV_vs_Response = []\n",
    "FaceV_vs_Response = []\n",
    "ColorV_vs_Response = []\n",
    "\n",
    "# Pearson correlations between conditions.\n",
    "for i in range(0,40):\n",
    "    [a,b] = scipy.stats.pearsonr(Face_Percep_Cluster[i,:], Face_Value_Cluster[i,:])\n",
    "    FaceP_vs_FaceV.append(a)\n",
    "    [a,b] = scipy.stats.pearsonr(Color_Percep_Cluster[i,:], Color_Value_Cluster[i,:])\n",
    "    ColorP_vs_ColorV.append(a)\n",
    "    [a,b] = scipy.stats.pearsonr(Face_Value_Cluster[i,:], Color_Value_Cluster[i,:])\n",
    "    FaceV_vs_ColorV.append(a)\n",
    "    [a,b] = scipy.stats.pearsonr(Face_Value_Cluster[i,:], Overall_Value_Cluster[i,:])\n",
    "    FaceV_vs_OverallV.append(a)\n",
    "    [a,b] = scipy.stats.pearsonr(Color_Value_Cluster[i,:], Overall_Value_Cluster[i,:])\n",
    "    ColorV_vs_OverallV.append(a)\n",
    "    [a,b] = scipy.stats.pearsonr(Overall_Value_Cluster[i,:], Response_Cluster[i,:])\n",
    "    OverallV_vs_Response.append(a)\n",
    "    [a,b] = scipy.stats.pearsonr(Face_Value_Cluster[i,:], Response_Cluster[i,:])\n",
    "    FaceV_vs_Response.append(a)\n",
    "    [a,b] = scipy.stats.pearsonr(Color_Value_Cluster[i,:], Response_Cluster[i,:])\n",
    "    ColorV_vs_Response.append(a)\n",
    "\n",
    "# Z-transform the data.\n",
    "FaceP_vs_FaceV_zscore = []\n",
    "ColorP_vs_ColorV_zscore = []\n",
    "FaceV_vs_ColorV_zscore = []\n",
    "FaceV_vs_OverallV_zscore = []\n",
    "ColorV_vs_OverallV_zscore  = []\n",
    "OverallV_vs_Response_zscore  = []\n",
    "FaceV_vs_Response_zscore = []\n",
    "ColorV_vs_Response_zscore  = []\n",
    "for i in range(0,40):\n",
    "    FaceP_vs_FaceV_zscore.append(.5*np.log((1+FaceP_vs_FaceV[i])/(1-FaceP_vs_FaceV[i])))\n",
    "    ColorP_vs_ColorV_zscore.append(.5*np.log((1+ColorP_vs_ColorV[i])/(1-ColorP_vs_ColorV[i])))\n",
    "    FaceV_vs_ColorV_zscore.append(.5*np.log((1+FaceV_vs_ColorV[i])/(1-FaceV_vs_ColorV[i])))\n",
    "    FaceV_vs_OverallV_zscore.append(.5*np.log((1+FaceV_vs_OverallV[i])/(1-FaceV_vs_OverallV[i])))\n",
    "    ColorV_vs_OverallV_zscore.append(.5*np.log((1+ColorV_vs_OverallV[i])/(1-ColorV_vs_OverallV[i])))\n",
    "    OverallV_vs_Response_zscore.append(.5*np.log((1+OverallV_vs_Response[i])/(1-OverallV_vs_Response[i])))\n",
    "    FaceV_vs_Response_zscore.append(.5*np.log((1+FaceV_vs_Response[i])/(1-FaceV_vs_Response[i])))\n",
    "    ColorV_vs_Response_zscore.append(.5*np.log((1+ColorV_vs_Response[i])/(1-ColorV_vs_Response[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=-0.010534812238418683, pvalue=0.9916482980362076, df=39)\n",
      "TtestResult(statistic=0.7062786811571646, pvalue=0.48421308506517524, df=39)\n",
      "TtestResult(statistic=0.3076986622318719, pvalue=0.7599489329262533, df=39)\n",
      "TtestResult(statistic=10.188189742359587, pvalue=1.5052183638571087e-12, df=39)\n",
      "TtestResult(statistic=6.407528523059508, pvalue=1.408006237336219e-07, df=39)\n",
      "TtestResult(statistic=10.999726051585997, pvalue=1.6094600148668403e-13, df=39)\n",
      "TtestResult(statistic=7.321733961448829, pvalue=7.781456552102176e-09, df=39)\n",
      "TtestResult(statistic=6.288211010171032, pvalue=2.0608778389558357e-07, df=39)\n"
     ]
    }
   ],
   "source": [
    "#One-sample ttest on z-scored data. \n",
    "print(scipy.stats.ttest_1samp(FaceP_vs_FaceV_zscore,popmean=0))\n",
    "print(scipy.stats.ttest_1samp(ColorP_vs_ColorV_zscore,popmean=0))\n",
    "print(scipy.stats.ttest_1samp(FaceV_vs_ColorV_zscore,popmean=0))\n",
    "print(scipy.stats.ttest_1samp(FaceV_vs_OverallV_zscore,popmean=0))\n",
    "print(scipy.stats.ttest_1samp(ColorV_vs_OverallV_zscore,popmean=0))\n",
    "print(scipy.stats.ttest_1samp(OverallV_vs_Response_zscore,popmean=0))\n",
    "print(scipy.stats.ttest_1samp(FaceV_vs_Response_zscore,popmean=0))\n",
    "print(scipy.stats.ttest_1samp(ColorV_vs_Response_zscore,popmean=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdr correction\n",
    "pvals = []\n",
    "stat,pval = scipy.stats.ttest_1samp(FaceP_vs_FaceV_zscore,popmean=0)\n",
    "pvals.append(pval)\n",
    "stat,pval = scipy.stats.ttest_1samp(ColorP_vs_ColorV_zscore,popmean=0)\n",
    "pvals.append(pval)\n",
    "stat,pval = scipy.stats.ttest_1samp(FaceV_vs_ColorV_zscore,popmean=0)\n",
    "pvals.append(pval)\n",
    "stat,pval = scipy.stats.ttest_1samp(FaceV_vs_OverallV_zscore,popmean=0)\n",
    "pvals.append(pval)\n",
    "stat,pval = scipy.stats.ttest_1samp(ColorV_vs_OverallV_zscore,popmean=0)\n",
    "pvals.append(pval)\n",
    "stat,pval = scipy.stats.ttest_1samp(OverallV_vs_Response_zscore,popmean=0)\n",
    "pvals.append(pval)\n",
    "\n",
    "reject_by, p_values_corrected_by, _, _ = multipletests(pvals,alpha=.05,method='fdr_bh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the cluster-averaged topos (top of spatial figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment each line as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegData, _, _ = get_eeg_behav_data('102')\n",
    "infoStructure = eegData.info\n",
    "#im, cn = mne.viz.plot_topomap(np.nanmean(Face_Percep_Cluster,axis=0),infoStructure, vlim=(-.003,.003),cmap='jet')\n",
    "#im, cn = mne.viz.plot_topomap(np.nanmean(Color_Percep_Cluster,axis=0),infoStructure, vlim=(-.001,.001),cmap='jet')\n",
    "#im, cn = mne.viz.plot_topomap(np.nanmean(Face_Value_Cluster,axis=0),infoStructure, vlim=(-.003,.003),cmap='jet')\n",
    "#im, cn = mne.viz.plot_topomap(np.nanmean(Color_Value_Cluster,axis=0),infoStructure, vlim=(-.002,.002),cmap='jet')\n",
    "#im, cn = mne.viz.plot_topomap(np.nanmean(Overall_Value_Cluster,axis=0),infoStructure, vlim=(-.006,.006),cmap='jet')\n",
    "im, cn = mne.viz.plot_topomap(np.nanmean(Response_Cluster,axis=0),infoStructure, vlim=(-.004,.004),cmap='jet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the histograms (bottom of spatial figure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment each collection of code as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(FaceP_vs_FaceV_zscore,range = (-2.23,2.23))\n",
    "#plt.axvline(x=0,c='black')\n",
    "#plt.ylim((0,18))\n",
    "#savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection','FaceP_vs_FaceV_zscore_reref.eps')\n",
    "#plt.savefig(savefig,format='eps')\n",
    "\n",
    "#plt.hist(ColorP_vs_ColorV_zscore,range = (-2.23,2.23))\n",
    "#plt.axvline(x=0,c='black')\n",
    "#plt.ylim((0,18))\n",
    "#savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection','ColorP_vs_ColorV_zscore_reref.eps')\n",
    "#plt.savefig(savefig,format='eps')\n",
    "\n",
    "#plt.hist(FaceV_vs_ColorV_zscore,range = (-2.23,2.23))\n",
    "#plt.axvline(x=0,c='black')\n",
    "#plt.ylim((0,18))\n",
    "#savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection','FaceV_vs_ColorV_zscore_reref.eps')\n",
    "#plt.savefig(savefig,format='eps')\n",
    "\n",
    "#plt.hist(FaceV_vs_OverallV_zscore,range = (-2.23,2.23))\n",
    "#plt.axvline(x=0,c='black')\n",
    "#plt.ylim((0,18))\n",
    "#savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection','FaceV_vs_OverallV_zscore_reref.eps')\n",
    "#plt.savefig(savefig,format='eps')\n",
    "\n",
    "#plt.hist(ColorV_vs_OverallV_zscore,range = (-2.23,2.23))\n",
    "#plt.axvline(x=0,c='black')\n",
    "#plt.ylim((0,18))\n",
    "#savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection','ColorV_vs_OverallV_zscore_reref.eps')\n",
    "#plt.savefig(savefig,format='eps')\n",
    "\n",
    "#plt.hist(OverallV_vs_Response_zscore,range = (-2.23,2.23))\n",
    "#plt.axvline(x=0,c='black')\n",
    "#plt.ylim((0,18))\n",
    "#savefig = os.path.join('GroupResults','guggenmos_noJitFix','Figures','finalSelection','OverallV_vs_Response_zscore_reref.eps')\n",
    "#plt.savefig(savefig,format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking correlations between adjacent clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of these values are reported in the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tests for within-subject stability of clusters.\n",
    "import scipy.stats\n",
    "r_scores1 = [];\n",
    "r_scores2 = [];\n",
    "r_scores3 = [];\n",
    "r_scores4 = [];\n",
    "\n",
    "## Adjust this as necessary for your condition.\n",
    "cluster1 = np.nanmean(Face_Value1_Patterns,axis=1)\n",
    "cluster2 = np.nanmean(Face_Value2_Patterns,axis=1)\n",
    "#cluster3 = np.nanmean(Color_Value3_Patterns,axis=1)\n",
    "#cluster4 = np.nanmean(Overall_Value4_Patterns,axis=1)\n",
    "#cluster5 = np.nanmean(Overall_Value5_Patterns,axis=1)\n",
    "\n",
    "for i in range (0,40):\n",
    "    [a,b] = scipy.stats.pearsonr(cluster1[i,:], cluster2[i,:])\n",
    "    r_scores1.append(a)\n",
    "    #[a,b] = scipy.stats.pearsonr(cluster2[i,:], cluster3[i,:])\n",
    "    #r_scores2.append(a)\n",
    "    #[a,b] = scipy.stats.pearsonr(cluster3[i,:], cluster4[i,:])\n",
    "    #r_scores3.append(a)\n",
    "    #[a,b] = scipy.stats.pearsonr(cluster4[i,:], cluster5[i,:])\n",
    "    #r_scores4.append(a)\n",
    "#fig, ax = plt.subplots()\n",
    "#img,_ = mne.viz.plot_topomap(r_scores,infoStructure,cmap='jet',axes=ax)\n",
    "#cbar = plt.colorbar(ax=ax,shrink=.75,orientation=\"vertical\",mappable=img)\n",
    "print(np.mean(r_scores1))\n",
    "print(np.mean(r_scores2))\n",
    "print(np.mean(r_scores3))\n",
    "print(np.mean(r_scores4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
